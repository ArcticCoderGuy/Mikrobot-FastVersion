"""
Test Suite for M5 BOS + M1 Retest Validation System Integration
Comprehensive testing of the integrated validation system components
"""

import asyncio
import unittest
from unittest.mock import Mock, MagicMock, patch
from datetime import datetime
import sys
import os

# Add src to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from core.validation_system_integration import ValidationSystemIntegration
from core.mcp_controller import MCPController
from core.validation_optimizer import ValidationResult
from core.dynamic_risk_manager import PositionSizingResult, RiskLevel, MarketCondition


class TestValidationSystemIntegration(unittest.TestCase):
    """Test cases for the integrated validation system"""
    
    def setUp(self):
        """Set up test environment"""
        self.mock_mcp_controller = Mock(spec=MCPController)
        self.integration_system = ValidationSystemIntegration(
            self.mock_mcp_controller, 
            account_balance=10000.0\n        )\n        \n        # Sample signal data for testing\n        self.sample_signal_data = {\n            'trace_id': 'test_trace_001',\n            'symbol': 'EURUSD',\n            'pattern_type': 'M5_BOS',\n            'direction': 'BUY',\n            'timeframe': 'M5',\n            'price_levels': {\n                'entry': 1.1000,\n                'stop_loss': 1.0950,\n                'take_profit': 1.1100,\n                'current_price': 1.1000,\n                'previous_high': 1.0995,\n                'previous_low': 1.0980,\n                'structure_break_level': 1.0995\n            },\n            'volume': {\n                'current_volume': 1500,\n                'avg_volume_20': 1000\n            },\n            'momentum': {\n                'momentum_score': 0.7,\n                'rsi': 60,\n                'macd_signal': 0.5\n            },\n            'market_data': {\n                'current_session': 'london',\n                'volatility_level': 'medium',\n                'news_risk': 'normal',\n                'trend_strength': 0.8\n            },\n            'timestamp': datetime.utcnow().isoformat()\n        }\n    \n    def test_initialization(self):\n        \"\"\"Test system initialization\"\"\"\n        self.assertIsNotNone(self.integration_system.product_owner)\n        self.assertIsNotNone(self.integration_system.validation_optimizer)\n        self.assertIsNotNone(self.integration_system.risk_manager)\n        self.assertIsNotNone(self.integration_system.performance_monitor)\n        \n        # Check configuration\n        self.assertEqual(self.integration_system.config['performance_target_ms'], 100.0)\n        self.assertEqual(self.integration_system.config['min_confidence_threshold'], 0.6)\n    \n    @patch('core.validation_system_integration.time.perf_counter')\n    async def test_successful_signal_processing(self, mock_time):\n        \"\"\"Test successful signal processing through complete pipeline\"\"\"\n        \n        # Mock timing\n        mock_time.side_effect = [\n            0.0,    # processing_start\n            0.05,   # validation_start\n            0.08,   # validation_end\n            0.09,   # risk_calc_start\n            0.095,  # risk_calc_end\n            0.1     # processing_end\n        ]\n        \n        # Mock validation optimizer result\n        mock_validation_result = ValidationResult(\n            trace_id='test_trace_001',\n            strategic_approved=True,\n            technical_valid=True,\n            overall_approved=True,\n            strategic_confidence=0.85,\n            technical_confidence=0.80,\n            combined_confidence=0.82,\n            validation_latency_ms=80.0,\n            strategic_latency_ms=40.0,\n            technical_latency_ms=40.0,\n            cache_hit=False,\n            reasons=['Both strategic and technical validation passed'],\n            details={'strategic_result': {}, 'technical_result': {}},\n            timestamp=datetime.utcnow()\n        )\n        \n        # Mock validation optimizer\n        self.integration_system.validation_optimizer.validate_signal_optimized = MagicMock(\n            return_value=mock_validation_result\n        )\n        \n        # Process signal\n        result = await self.integration_system.process_trading_signal_complete(self.sample_signal_data)\n        \n        # Assertions\n        self.assertTrue(result.final_approval)\n        self.assertEqual(result.trace_id, 'test_trace_001')\n        self.assertEqual(result.symbol, 'EURUSD')\n        self.assertEqual(result.pattern_type, 'M5_BOS')\n        self.assertEqual(result.overall_confidence, 0.82)\n        self.assertGreater(result.recommended_position_size, 0.0)\n        self.assertGreater(result.expected_risk_reward, 0.0)\n        \n        # Check timing targets\n        self.assertLess(result.total_processing_time_ms, 120.0)  # Allow some tolerance\n        \n        # Verify validation optimizer was called\n        self.integration_system.validation_optimizer.validate_signal_optimized.assert_called_once()\n    \n    async def test_signal_rejection_low_confidence(self):\n        \"\"\"Test signal rejection due to low confidence\"\"\"\n        \n        # Mock low confidence validation result\n        mock_validation_result = ValidationResult(\n            trace_id='test_trace_002',\n            strategic_approved=False,\n            technical_valid=True,\n            overall_approved=False,\n            strategic_confidence=0.5,  # Below threshold\n            technical_confidence=0.75,\n            combined_confidence=0.55,\n            validation_latency_ms=75.0,\n            strategic_latency_ms=45.0,\n            technical_latency_ms=30.0,\n            cache_hit=False,\n            reasons=['Strategic confidence below threshold'],\n            details={},\n            timestamp=datetime.utcnow()\n        )\n        \n        self.integration_system.validation_optimizer.validate_signal_optimized = MagicMock(\n            return_value=mock_validation_result\n        )\n        \n        # Process signal\n        signal_data = self.sample_signal_data.copy()\n        signal_data['trace_id'] = 'test_trace_002'\n        \n        result = await self.integration_system.process_trading_signal_complete(signal_data)\n        \n        # Assertions\n        self.assertFalse(result.final_approval)\n        self.assertIn('Strategic confidence below threshold', result.rejection_reasons)\n        self.assertEqual(result.recommended_position_size, 0.0)\n    \n    def test_m5_bos_pattern_specific_validation(self):\n        \"\"\"Test M5 BOS pattern specific validation logic\"\"\"\n        \n        # Test M5 BOS specific signal data\n        m5_bos_signal = {\n            **self.sample_signal_data,\n            'pattern_type': 'M5_BOS',\n            'structure_analysis': {\n                'break_strength': 0.8,\n                'structure_significance': 'high'\n            },\n            'volume_confirmation': {\n                'volume_ratio': 1.6,  # Above 1.5x average\n                'confirmed': True\n            }\n        }\n        \n        # Verify pattern-specific logic would be applied\n        self.assertEqual(m5_bos_signal['pattern_type'], 'M5_BOS')\n        self.assertIn('structure_analysis', m5_bos_signal)\n        self.assertIn('volume_confirmation', m5_bos_signal)\n    \n    def test_m1_retest_pattern_specific_validation(self):\n        \"\"\"Test M1 retest pattern specific validation logic\"\"\"\n        \n        # Test M1 retest specific signal data\n        m1_retest_signal = {\n            **self.sample_signal_data,\n            'pattern_type': 'M1_BREAK_RETEST',\n            'price_levels': {\n                **self.sample_signal_data['price_levels'],\n                'break_level': 1.1000,\n                'retest_level': 1.0998  # Within 0.8 pip deviation\n            },\n            'retest_quality': {\n                'deviation_pips': 0.2,  # Well within 0.8 pip threshold\n                'pattern_score': 0.9,\n                'time_factor': 0.8\n            }\n        }\n        \n        # Verify pattern-specific logic would be applied\n        self.assertEqual(m1_retest_signal['pattern_type'], 'M1_BREAK_RETEST')\n        self.assertIn('retest_quality', m1_retest_signal)\n        self.assertEqual(m1_retest_signal['retest_quality']['deviation_pips'], 0.2)\n    \n    def test_dynamic_position_sizing(self):\n        \"\"\"Test dynamic position sizing based on confidence\"\"\"\n        \n        # Test high confidence scenario\n        high_confidence_data = {\n            'symbol': 'EURUSD',\n            'direction': 'BUY',\n            'validation_confidence': 0.9,  # High confidence\n            'market_condition': MarketCondition.OPTIMAL\n        }\n        \n        # Test low confidence scenario\n        low_confidence_data = {\n            'symbol': 'EURUSD',\n            'direction': 'BUY',\n            'validation_confidence': 0.65,  # Lower confidence\n            'market_condition': MarketCondition.UNFAVORABLE\n        }\n        \n        # High confidence should result in larger position size\n        # Low confidence should result in smaller position size\n        # This would be tested through the DynamicRiskManager component\n        \n        self.assertGreater(high_confidence_data['validation_confidence'], \n                          low_confidence_data['validation_confidence'])\n    \n    def test_performance_monitoring_integration(self):\n        \"\"\"Test performance monitoring integration\"\"\"\n        \n        # Enable performance monitoring\n        self.integration_system.config['enable_performance_monitoring'] = True\n        \n        # Mock performance monitor\n        mock_record_validation = Mock()\n        self.integration_system.performance_monitor.record_validation_performance = mock_record_validation\n        \n        # This would be called during signal processing\n        # Verify the integration exists\n        self.assertTrue(self.integration_system.config['enable_performance_monitoring'])\n        self.assertIsNotNone(self.integration_system.performance_monitor)\n    \n    def test_sub_100ms_performance_target(self):\n        \"\"\"Test sub-100ms performance target tracking\"\"\"\n        \n        # Test performance target configuration\n        self.assertEqual(self.integration_system.config['performance_target_ms'], 100.0)\n        \n        # Test metrics initialization\n        self.assertIn('sub_100ms_achievement_rate', self.integration_system.integration_metrics)\n        \n        # Performance would be measured during actual signal processing\n        # This test verifies the tracking mechanism exists\n        self.assertIsNotNone(self.integration_system.integration_metrics)\n    \n    def test_error_handling(self):\n        \"\"\"Test error handling and resilience\"\"\"\n        \n        # Mock validation optimizer to raise exception\n        self.integration_system.validation_optimizer.validate_signal_optimized = MagicMock(\n            side_effect=Exception(\"Test validation error\")\n        )\n        \n        # Process should handle error gracefully\n        async def test_error_processing():\n            result = await self.integration_system.process_trading_signal_complete(self.sample_signal_data)\n            \n            self.assertFalse(result.final_approval)\n            self.assertIn('Integration error', result.rejection_reasons[0])\n            self.assertEqual(result.recommended_position_size, 0.0)\n            self.assertEqual(result.risk_level, 'critical')\n        \n        # Run async test\n        asyncio.run(test_error_processing())\n    \n    def test_configuration_management(self):\n        \"\"\"Test system configuration management\"\"\"\n        \n        # Test initial configuration\n        initial_target = self.integration_system.config['performance_target_ms']\n        self.assertEqual(initial_target, 100.0)\n        \n        # Test configuration update\n        config_updates = {\n            'performance_target_ms': 80.0,\n            'min_confidence_threshold': 0.7\n        }\n        \n        self.integration_system.configure_system(config_updates)\n        \n        self.assertEqual(self.integration_system.config['performance_target_ms'], 80.0)\n        self.assertEqual(self.integration_system.config['min_confidence_threshold'], 0.7)\n    \n    def test_comprehensive_metrics_collection(self):\n        \"\"\"Test comprehensive metrics collection\"\"\"\n        \n        metrics = self.integration_system.get_comprehensive_metrics()\n        \n        # Verify all metric categories are present\n        self.assertIn('integration_metrics', metrics)\n        self.assertIn('validation_optimizer_metrics', metrics)\n        self.assertIn('risk_manager_metrics', metrics)\n        self.assertIn('performance_monitor_metrics', metrics)\n        self.assertIn('product_owner_status', metrics)\n        self.assertIn('system_configuration', metrics)\n        \n        # Verify integration metrics structure\n        integration_metrics = metrics['integration_metrics']\n        self.assertIn('total_signals_processed', integration_metrics)\n        self.assertIn('successful_integrations', integration_metrics)\n        self.assertIn('avg_total_processing_time_ms', integration_metrics)\n        self.assertIn('sub_100ms_achievement_rate', integration_metrics)\n    \n    async def test_health_check(self):\n        \"\"\"Test system health check functionality\"\"\"\n        \n        # Mock component status methods\n        self.integration_system.product_owner.get_comprehensive_status = MagicMock(\n            return_value={\n                'agent_info': {'is_active': True},\n                'metrics': {'messages_received': 10}\n            }\n        )\n        \n        self.integration_system.validation_optimizer.get_performance_metrics = MagicMock(\n            return_value={\n                'validation_metrics': {'performance_target_met_rate': 0.85}\n            }\n        )\n        \n        self.integration_system.risk_manager.get_risk_metrics = MagicMock(\n            return_value={\n                'portfolio_state': {'current_drawdown': 0.05}\n            }\n        )\n        \n        self.integration_system.performance_monitor.get_comprehensive_metrics = MagicMock(\n            return_value={\n                'active_alerts': []\n            }\n        )\n        \n        # Perform health check\n        health_status = await self.integration_system.health_check()\n        \n        # Verify health check structure\n        self.assertIn('overall_status', health_status)\n        self.assertIn('components', health_status)\n        self.assertIn('timestamp', health_status)\n        \n        # Verify component checks\n        components = health_status['components']\n        self.assertIn('product_owner', components)\n        self.assertIn('validation_optimizer', components)\n        self.assertIn('risk_manager', components)\n        self.assertIn('performance_monitor', components)\n    \n    def test_multi_asset_support(self):\n        \"\"\"Test multi-asset support (forex, crypto, indices, stocks)\"\"\"\n        \n        # Test different asset types\n        test_assets = [\n            {'symbol': 'EURUSD', 'asset_type': 'forex'},\n            {'symbol': 'BTCUSD', 'asset_type': 'crypto'},\n            {'symbol': 'XAUUSD', 'asset_type': 'metal'},\n            {'symbol': 'US30', 'asset_type': 'index'}\n        ]\n        \n        for asset in test_assets:\n            # Verify system can handle different asset types\n            signal_data = {\n                **self.sample_signal_data,\n                'symbol': asset['symbol']\n            }\n            \n            # The system should be able to process any symbol\n            self.assertIsInstance(signal_data['symbol'], str)\n            self.assertTrue(len(signal_data['symbol']) > 0)\n\n\nclass TestValidationSystemPerformance(unittest.TestCase):\n    \"\"\"Performance-specific test cases\"\"\"\n    \n    def setUp(self):\n        self.mock_mcp_controller = Mock(spec=MCPController)\n        self.integration_system = ValidationSystemIntegration(\n            self.mock_mcp_controller,\n            account_balance=10000.0\n        )\n    \n    def test_performance_target_configuration(self):\n        \"\"\"Test performance target configuration\"\"\"\n        \n        # Verify sub-100ms target is configured\n        self.assertEqual(self.integration_system.config['performance_target_ms'], 100.0)\n        \n        # Verify performance tracking is enabled\n        self.assertTrue(self.integration_system.config['enable_performance_monitoring'])\n    \n    def test_caching_configuration(self):\n        \"\"\"Test validation caching configuration\"\"\"\n        \n        # Verify caching is enabled by default\n        self.assertTrue(self.integration_system.config['enable_validation_caching'])\n        \n        # Verify validation optimizer has caching capability\n        self.assertIsNotNone(self.integration_system.validation_optimizer)\n        self.assertTrue(hasattr(self.integration_system.validation_optimizer, 'validation_cache'))\n    \n    def test_parallel_processing_capability(self):\n        \"\"\"Test parallel validation processing capability\"\"\"\n        \n        # Verify validation optimizer exists (handles parallel processing)\n        self.assertIsNotNone(self.integration_system.validation_optimizer)\n        \n        # Verify method exists for optimized validation\n        self.assertTrue(hasattr(\n            self.integration_system.validation_optimizer, \n            'validate_signal_optimized'\n        ))\n\n\nif __name__ == '__main__':\n    # Configure logging for tests\n    import logging\n    logging.basicConfig(level=logging.INFO)\n    \n    # Run tests\n    unittest.main(verbosity=2)"